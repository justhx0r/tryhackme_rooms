{'image': 'https://tryhackme-images.s3.amazonaws.com/room-icons/24de724519d5a2f65efc6ae06fc2bbd9.png', 'title': 'Google Dorking', 'description': 'Explaining how Search Engines work and leveraging them into finding hidden content!', 'code': 'googledorking', 'users': 96598, 'tags': ['osint', 'google dorking', 'dork', 'beginner', 'web app', 'research', 'researching'], 'type': 'walkthrough', 'difficulty': 'easy', 'userCompleted': False, 'upVotes': 4251, 'created': '2020-03-29T23:21:37.129Z', 'published': '2020-03-29T21:26:20.809Z', 'freeToUse': True, 'businessOnly': False, 'headerImage': 'https://i.imgur.com/9YpAbRk.png', 'creator': 'cmnatic', 'tasks': [{'taskTitle': "Ye Ol' Search Engine", 'taskDesc': '<p>Google is arguably the most famous example of “Search\nEngines”, I mean who remembers Ask Jeeves? <strike><i>shudders</i></strike></p><p>Now it might be rather patronising explaining how these “Search Engines” work, but there’s a lot more going on behind the scenes then what we see.\nMore importantly, we can leverage this to our advantage to find all sorts of\nthings that a wordlist wouldn’t.\xa0<span style="font-size:1rem;">Researching as a whole - especially in the context of Cybersecurity encapsulates almost everything you do as a pentester. <a href="https://tryhackme.com/p/MuirlandOracle" target="_blank">MuirlandOracle</a>\xa0has created a <a href="https://tryhackme.com/room/introtoresearch" target="_blank">fantastic room</a> on learning the attitudes towards how to research, and what information you can gain from it exactly.</span></p><p>"Search Engines" such as Google are huge indexers –\nspecifically, indexers of content spread across the World Wide Web.</p><p>\n\n\n\n\n\n</p><p>These essentials in surfing the internet use “Crawlers” or\n“Spiders” to search for this content across the World Wide Web, which I will discuss in the next task.</p>', 'taskType': 'none', 'taskNo': 1, 'taskCreated': '2020-03-18T15:26:26.287Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>Roger dodger!</p>', 'hint': ''}]}, {'taskTitle': "Let's Learn About Crawlers", 'taskDesc': '<p style="text-align:center;"><span style="font-size:24px;">What are Crawlers and how do They Work?</span></p><p><span style="font-size:1rem;">These crawlers discover content through various means. One being by pure discovery, where a URL is visited by the crawler and information regarding the content type of the website is returned to the search engine. In fact, there are lots of information modern crawlers scrape – but we will discuss how this is used later. Another method crawlers use to discover content is by following any and all URLs found from previously crawled websites. Much like a virus in the sense that it will want to traverse/spread to everything it can.</span><br /></p><p><br /></p><p style="text-align:center;"><span style="font-size:24px;">Let\'s Visualise Some Things...</span></p><p></p><div style="text-align:center;"><br /></div>The diagram below is a high-level abstraction of how these web crawlers work. Once a web crawler discovers a domain such as <b>mywebsite.com</b>, it will index the entire contents of the domain, looking for keywords and other miscellaneous information - but I will discuss this miscellaneous information later.<p></p><p><br /></p><p><img src="https://i.imgur.com/4nrDDa0.png" style="width:671px;" /></p><p><span style="font-size:1rem;"><br /></span></p><p><span style="font-size:1rem;">In the diagram above, "<b>mywebsite.com</b>" has been scraped as having the keywords as “Apple” “Banana" and “Pear”. These keywords are stored in a dictionary by the crawler, who then returns these to the search engine i.e. Google. Because of this persistence, Google now knows that the domain “<b>mywebsite.com</b>” has the keywords “Apple", “Banana” and “Pear”. As only one website has been crawled, if a user was to search for “Apple”...“<b>mywebsite.com</b>” would appear.\xa0</span><span style="font-size:1rem;">This would result in the same behaviour if the user was to search for “Banana”. As the indexed contents from the crawler report the domain as having “Banana”, it will be displayed to the user.</span></p><p><br />As illustrated below, a user submits a query to the search engine of “Pears". Because the search engine only has the contents of one website that has been crawled with the keyword of “Pears” it will be the only domain that is presented to the user.\xa0<br /></p><p><img src="https://i.imgur.com/nbbsAp4.png" style="width:675px;" /></p><p><span style="font-size:1rem;">However, as we previously mentioned, </span><strong>crawlers attempt to traverse, termed as crawling, every URL and file that they can find!</strong><span style="font-size:1rem;"> Say if “</span><b style="font-size:1rem;">mywebsite.com</b><span style="font-size:1rem;">” had the same keywords as before (“Apple", “Banana” and “Pear”), but also had a URL to another website “</span><b style="font-size:1rem;">anotherwebsite.com</b><span style="font-size:1rem;">”, the crawler will then attempt to traverse everything on that URL (<b>anotherwebsite.com</b>) and retrieve the contents of everything within that domain respectively.</span><br /></p><p><br />This is illustrated in the diagram below. The crawler initially finds “<b>mywebsite.com</b>”, where it crawls the contents of the website - finding the same keywords (“Apple", “Banana” and “Pear”) as before, but it has additionally found an external URL. Once the crawler is complete on “<b>mywebsite.com</b>”, it\'ll proceed to crawl the contents of the website “<b>anotherwebsite.com</b>”, where the keywords ("Tomatoes", “Strawberries” and “Pineapples”) are found on it. The crawler\'s dictionary now contains the contents of both “<b>mywebsite.com</b>” and “<b>anotherwebsite.com</b>”, which is then stored and saved within the search engine.</p><p><br /></p><p></p><p><img src="https://i.imgur.com/CIM2c6N.png" style="width:811px;" /></p><p><br /></p><p style="text-align:center;"><span style="font-size:24px;">Recapping</span></p><p>So to recap, the search engine now has knowledge of two domains that have been crawled:<br />    1. mywebsite.com<br />    2. anotherwebsite.com</p><p><span style="font-size:1rem;">Although note that “</span><b style="font-size:1rem;">anotherwebsite.com</b><span style="font-size:1rem;">” was only crawled because it was referenced by the first domain “</span><b style="font-size:1rem;">mywebsite.com</b><span style="font-size:1rem;">”. Because of this reference, the search engine knows the following about the two domains:</span><br /></p><p><br /></p><table class="table table-bordered"><tbody><tr><td><b>Domain Name</b></td><td><b>Keyword</b></td></tr><tr><td>mywebsite.com</td><td>Apples</td></tr><tr><td>mywebsite.com<br /></td><td>Bananas</td></tr><tr><td>mywebsite.com<br /></td><td>Pears</td></tr><tr><td>anotherwebsite.com</td><td>Tomatoes</td></tr><tr><td>anotherwebsite.com</td><td>Strawberries</td></tr><tr><td>anotherwebsite.com</td><td>Pineapples</td></tr></tbody></table><p>Or as illustrated below:</p><p></p><p><img src="https://i.imgur.com/BJeI451.png" style="width:492px;height:398.508px;" /><span style="font-size:1rem;"><br /></span></p><p><span style="font-size:1rem;"><br /></span></p><p><span style="font-size:1rem;">Now that the search engine has some knowledge about keywords, say if a user was to search for “Pears” the domain “</span><b style="font-size:1rem;">mywebsite.com</b><span style="font-size:1rem;">” will be displayed - as it is the only crawled domain containing "Pears":</span><br /></p><p></p><p><img src="https://i.imgur.com/lBD6FPD.png" style="width:615.273px;height:388.594px;" /><br /></p><p>Likewise, say in this case the user now searches for "Strawberries". The domain "<b>anotherwebsite.com</b>" will be displayed, as it is the only domain that has been crawled by the search engine that contains the keyword "Strawberries":</p><p><img src="https://i.imgur.com/1LGoslC.png" style="width:594px;height:315.031px;" /><br /></p><p><br /></p><p>This is great...But imagine if a website had multiple external URL\'s (as they often do!) That\'ll require a lot of crawling to take place. There\'s always the chance that another website might have similar information as of that another website crawled - right? So how does the "Search Engine" decide on the hierarchy of the domains that are displayed to the user?</p><p>In the diagram below in this instance, if the user was to search for a keyword such as "Tomatoes" (which websites 1-3 contain) who decides what website gets displayed in what order?</p><p><img src="https://i.imgur.com/OG2Fgsx.png" style="font-size:1rem;width:610.449px;height:326.047px;" /></p><p><span style="font-size:1rem;"><br /></span></p><p><span style="font-size:1rem;">A logical presumption would be that website 1 -&gt; 3 would be displayed...But that\'s not how real-world domains work and/or are named.</span></p><p><span style="font-size:1rem;">So, who (or what) decides the hierarchy? Well...</span></p>', 'taskType': 'none', 'taskNo': 2, 'taskCreated': '2020-03-18T02:55:04.954Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>Name the key term\xa0of what a "Crawler" is used to do</p>', 'hint': ''}, {'questionNo': 2, 'question': '<p>What is the name of the technique that "Search Engines" use to retrieve this information about websites?</p>', 'hint': ''}, {'questionNo': 3, 'question': '<p>What is an example of the type of contents that could be gathered from a website?</p>', 'hint': ''}]}, {'taskTitle': 'Enter: Search Engine Optimisation', 'taskDesc': '<p style="text-align:center"><span style="font-size:24px">Search Engine Optimisation</span></p><p>Search Engine Optimisation or SEO is a prevalent and lucrative topic in modern-day search engines. In fact, so much so, that entire businesses capitalise on improving a domains SEO “ranking”. At an abstract view, search engines will “prioritise” those domains that are easier to index. There are many factors in how “optimal” a domain is - resulting in something similar to a point-scoring system.</p><p><span style="font-size:1rem"><br /></span></p><p><span style="font-size:1rem">To highlight a few influences on how these points are scored, factors such as:</span><br /></p><p>• How responsive your website is to the different browser types I.e. Google Chrome, Firefox and Internet Explorer - this includes Mobile phones!</p><p>• How easy it is to crawl your website (or if crawling is even allowed ...but we\'ll come to this later) through the use of "Sitemaps"</p><p>• What kind of keywords your website has (i.e. In our examples if the user was to search for a query like “Colours” no domain will be returned - as the search engine has not (yet) crawled a domain that has any keywords to do with “Colours”</p><p><br /></p><p>There is a lot of complexity in how the various search engines individually "point-score" or rank these domains - including vast algorithms. Naturally, the companies running these search engines such as Google don\'t share exactly how the hierarchic view of domains ultimately ends up. Although, as these are businesses at the end of the day, you can pay to advertise/boost the order of which your domain is displayed.</p><p><span style="font-size:1rem"><br /></span></p><p><span style="font-size:1rem">There are various online tools - sometimes provided by the search engine providers themselves that will show you just how optimised your domain is. For example, let\'s use </span><a href="https://web.dev" target="_blank">Google\'s Site Analyser</a><span style="font-size:1rem"> to check the rating of </span><a href="https://tryhackme.com" target="_blank">TryHackMe</a><span style="font-size:1rem">:</span><br /></p><p style="text-align:center"><img src="https://i.imgur.com/kvaFolh.png" style="width:953.111px;height:233.345px" /><br /></p><p></p><p><br /></p><p style="text-align:center"><img src="https://i.imgur.com/6rFnpVc.png" style="width:851.111px;height:514.619px" /><br /></p><p>According to this tool, TryHackMe has an SEO rating of <b>85/100</b> (as of 14/11/2020). That\'s not too bad and it\'ll show the justifications as to how this score was calculated below on the page.</p><p><br /></p><p style="text-align:center"><span style="font-size:24px">But...Who or What Regulates these "Crawlers"?</span></p><p style="text-align:left"><span style="font-size:16px">Aside from the search engines who provide these "Crawlers", website/web-server owners themselves ultimately stipulate what content "Crawlers" can scrape. Search engines will want to retrieve <b>everything </b>from a website - but there are a few cases where we wouldn\'t want <b>all </b>of the contents of our website to be indexed! Can you think of any...? How about a secret administrator login page? We don\'t want <b>everyone</b> to be able to find that directory - especially through a google search.</span></p><p style="text-align:left">Introducing Robots.txt...\xa0</p>', 'taskType': 'none', 'taskNo': 3, 'taskCreated': '2020-03-18T11:54:59.736Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>Use the same <a href="https://web.dev/measure/" target="_blank">SEO checkup tool</a> and other online alternatives to see how their results compare for <a href="https://tryhackme.com" target="_blank">https://tryhackme.com</a> and <a href="http://googledorking.cmnatic.co.uk" target="_blank">http://googledorking.cmnatic.co.uk</a></p>\n  \n  \n  ', 'hint': ''}]}, {'taskTitle': 'Beepboop - Robots.txt', 'taskDesc': '<p style="text-align:center;"><span style="font-size:24px;">\ufeff</span><span style="font-size:24px;">\ufeff</span><span style="font-size:24px;">Robots.txt</span></p><p style="text-align:left;">Similar to "Sitemaps" which we will later discuss, this file is the first thing indexed by "Crawlers" when visiting a website.</p><p style="text-align:left;"><br /></p><p style="text-align:center;"><span style="font-size:24px;">But what is it?</span></p><p>This file must be served at the root directory - specified by the webserver itself. Looking at this files extension of <b>.txt</b>, its fairly safe to assume that it is a text file.</p><p>The text file defines the permissions the "Crawler" has to the website. For example, what type of "Crawler" is allowed (I.e. You only want Google\'s "Crawler" to index your site and not MSN\'s). Moreover, Robots.txt can specify what files and directories that we do or don\'t want to be indexed by the "Crawler".</p><p>A very basic markup of a Robots.txt is like the following:</p><p><img src="https://i.imgur.com/wZ3lo4B.png" style="width:569.901px;height:149.083px;" /><br /></p><p><br /></p><p>Here we have a few keywords...</p><table class="table table-bordered"><tbody><tr><td>Keyword</td><td>Function</td></tr><tr><td>User-agent</td><td>Specify the type of "Crawler" that can index your site (the asterisk being a wildcard, allowing <b>all "User-agents"</b></td></tr><tr><td>Allow</td><td>Specify the directories or file(s) that the "Crawler"\xa0<b>can</b> index</td></tr><tr><td>Disallow</td><td>Specify the directories or file(s) that the "Crawler"\xa0<b>cannot </b>index</td></tr><tr><td>Sitemap</td><td>Provide a reference to where the sitemap is located (improves SEO as previously discussed, we\'ll come to sitemaps in the next task)</td></tr></tbody></table><p><br /></p><p>In this case:</p><p>1. Any "Crawler" can index the site</p><p>2. The "Crawler" is allowed to index the entire contents of the site</p><p>3. The "Sitemap" is located at <a href="http://mywebsite.com/sitemap.xml">http://mywebsite.com/sitemap.xml</a><a href="http://mywebsite.com/sitemap.xml"></a></p><p><br /></p><p>Say we wanted to hide directories or files from a "Crawler"? Robots.txt works on a "blacklisting" basis. Essentially, <b>unless told otherwise</b>, the Crawler will index whatever it can find.</p><p><img src="https://i.imgur.com/audlFn8.png" style="width:494.117px;height:172.014px;" /></p><p>In this case:</p><p>1. Any "Crawler" can index the site<br /></p><p>2. The "Crawler" can index every other content that isn\'t contained within "/super-secret-directory/".</p><p>Crawlers also know the differences between sub-directories, directories and files. Such as in the case of the second "Disallow:" (<span style="font-size:1rem;">"/not-a-secret/but-this-is/")</span></p><p><span style="font-size:1rem;">The "Crawler" will index all the contents within "<b>/not-a-secret/</b>", but will not index anything contained within the sub-directory <b>"/but-this-is/"</b>.</span></p><p><span style="font-size:1rem;">3. The "Sitemap" is located at\xa0</span><a href="http://mywebsite.com/sitemap.xml">http://mywebsite.com/sitemap.xml</a><a href="http://mywebsite.com/sitemap.xml"></a></p><p><br /></p><p style="text-align:center;"><span style="font-size:24px;">What if we Only Wanted Certain "Crawlers" to Index our Site?</span></p><p>We can stipulate so, such as in the picture below:</p><p><img src="https://i.imgur.com/LxitBJs.png" style="width:446.497px;height:195.24px;" /></p><p>In this case:</p><p>1. The "Crawler" "Googlebot" is allowed to index the entire site ("Allow: /")</p><p>2. The "Crawler" "msnbot" is not allowed to index the site (Disallow: /")</p><p><br /></p><p style="text-align:center;"><span style="font-size:24px;">How about Preventing Files From Being Indexed?</span>\xa0</p><p>Whilst you can make manual entries for every file extension that you don\'t want to be indexed, you will have to provide the directory it is within, as well as the full filename. Imagine if you had a huge site! What a pain...Here\'s where we can use a bit of <a href="https://www.rexegg.com/regex-quickstart.html" target="_blank">regexing</a>.</p><p><img src="https://i.imgur.com/mzDqFVY.png" style="width:456.88px;height:164.42px;" /></p><p>In this case:</p><p>1. Any "Crawler" can index the site</p><p>2. However, the "Crawler" cannot index <b>any </b>file that has the extension of <b>.ini </b>within any directory/sub-directory using ("$") of the site.</p><p>3.\xa0<span style="font-size:1rem;">The "Sitemap" is located at\xa0</span><a href="http://mywebsite.com/sitemap.xml">http://mywebsite.com/sitemap.xml</a></p><p>Why would you want to hide a <b>.ini</b> file for example? Well, files like this contain sensitive configuration details. Can you think of any other file formats that might contain sensitive information?</p><p><br /></p>', 'taskType': 'none', 'taskNo': 4, 'taskCreated': '2020-03-22T12:39:08.164Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>Where would "robots.txt" be located on the domain "<b>ablog.com</b>"</p>', 'hint': 'full path!'}, {'questionNo': 2, 'question': '<p>If a website was to have a sitemap, where would that be located?</p>', 'hint': ''}, {'questionNo': 3, 'question': 'How would we only allow "Bingbot" to index the website?', 'hint': ''}, {'questionNo': 4, 'question': '<p>How would we prevent a "Crawler" from indexing the directory "/dont-index-me/"?<br /></p>', 'hint': ''}, {'questionNo': 5, 'question': '<p>What is the extension of a Unix/Linux system configuration file that we might want to hide from "Crawlers"?</p>', 'hint': 'system files are usually 3/4 characters!'}]}, {'taskTitle': 'Sitemaps', 'taskDesc': '<p style="text-align:center"><span style="font-size:24px">Sitemaps</span></p><p></p><div style="text-align:left"><span style="font-size:1rem">Comparable to geographical maps in real life, “Sitemaps” are just that - but for websites!</span></div><br />“Sitemaps” are indicative resources that are helpful for crawlers, as they specify the necessary routes to find content on the domain. The below illustration is a good example of the structure of a website, and how it may look on a "Sitemap":<p></p><p><img src="https://i.imgur.com/L5WqJU4.png" style="width:626.997px" /></p><p><span style="font-size:1rem"><br /></span></p><p><span style="font-size:1rem">The blue rectangles represent the <b>route</b> to nested-content, similar to a directory I.e. “Products” for a store. Whereas, the green rounded-rectangles represent an actual page. However, this is for illustration purposes only - “Sitemaps” don\'t look like this in the real world. They look something much more similar to this:</span><br /></p><p><br /></p><p><img src="https://i.imgur.com/12Yxcn5.png" style="width:1046.04px" /></p><p>“Sitemaps” are XML formatted. I won\'t explain the structure of this file-formatting as the room <a href="https://tryhackme.com/jr/xxe" target="_blank">XXE</a>\xa0created by <a href="https://tryhackme.com/p/falconfeast" target="_blank">falconfeast</a>\xa0does a mighty fine job of this.</p><p>The presence of "Sitemaps" holds a fair amount of weight in influencing the "optimisation" and favorability of a website. As we discussed in the "Search Engine Optimisation" task, these maps make the traversal of content much easier for the crawler!</p><p><br /></p><p style="text-align:center"><span style="font-size:24px">Why are "Sitemaps" so Favourable for Search Engines?</span></p><p style="text-align:left">Search engines are lazy! Well, better yet - search engines have a lot of data to process. The efficiency of how this data is collected is paramount. Resources like "Sitemaps" are extremely helpful for "Crawlers" as the necessary routes to content are already provided! All the crawler has to do is scrape this content - rather than going through the process of manually finding and scraping. Think of it as using a wordlist to find files instead of randomly guessing their names!</p><p style="text-align:left"><br /></p><p style="text-align:left">The easier a website is to "Crawl", the more optimised it is for the "Search Engine"</p>', 'taskType': 'none', 'taskNo': 5, 'taskCreated': '2020-03-18T12:35:13.929Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>What is the typical file structure of a "Sitemap"?</p>', 'hint': ''}, {'questionNo': 2, 'question': '<p>What real life example can "Sitemaps" be compared to?</p>', 'hint': ''}, {'questionNo': 3, 'question': '<p>Name the keyword for the path taken for content on a website</p>', 'hint': ''}]}, {'taskTitle': 'What is Google Dorking?', 'taskDesc': '<p></p><p></p><div style="text-align:center;"><span style="font-size:24px;">Using Google for Advanced Searching</span></div><div style="text-align:center;"><br /></div>As we have previously discussed, Google has a lot of websites crawled and indexed. Your average Joe uses Google to look up Cat pictures (I\'m more of a Dog person myself...). Whilst Google will have many Cat pictures indexed ready to serve to Joe, this is a rather trivial use of the search engine in comparison to what it can be used for.<br />For example, we can add operators such as that from programming languages to either increase or decrease our search results - or perform actions such as arithmetic!<p></p><p><img src="https://i.imgur.com/hrfWM6i.png" style="width:670.354px;height:348.636px;" /><br /><br />Say if we wanted to narrow down our search query, we can use quotation marks. Google will interpret everything in between these quotation marks as exact and only return the results of the exact phrase provided...Rather useful to filter through the rubbish that we don\'t need as we have done so below:</p><p><img src="https://i.imgur.com/pJSW4ou.png" style="width:639.872px;height:720.868px;" /><br /></p><p></p><p><br /></p><div style="text-align:center;"><span style="font-size:24px;">Refining our Queries</span></div><div style="text-align:center;"><br /></div>We can use terms such as “<strong>site</strong>” (such as bbc.co.uk) and a query (such as "gchq news") to search the specified site for the keyword we have provided to filter out content that may be harder to find otherwise. For example, using the “site” and "query" of "bbc" and "gchq", we have modified the order of which Google returns the results.<br /><br />In the screenshot below, searching for “gchq news” returns approximately 1,060,000 results from Google. The website that we want is ranked behind GCHQ\'s actual website:<p></p><p><img src="https://i.imgur.com/b4duG6S.png" style="width:692.079px;height:341.476px;" /><br /><br />But we don\'t want that...We wanted “<strong>bbc</strong><strong>.co.</strong><strong>uk</strong>” first, so let\'s refine our search using the “<strong>site</strong>” term. Notice how in the screenshot below, Google returns with much fewer results? Additionally, the page that we didn\'t want has disappeared, leaving the site that we did actually want!\xa0</p><p><img src="https://i.imgur.com/dG3e64O.png" style="width:651.339px;height:323.25px;" /><br /><br />Of course, in this case, GCHQ is quite a topic of discussion - so there\'ll be a load of results regardless.</p><p><br /></p><p></p><div style="text-align:center;"><span style="font-size:24px;">So What Makes "Google Dorking" so Appealing?</span></div><div style="text-align:center;"><span style="font-size:24px;"><br /></span></div><div style="text-align:left;">First of all - and the important part - it\'s legal! It\'s all indexed, publicly available information. However, what you do with this is where the question of legality comes in to play...</div><div style="text-align:left;"><br /></div><div style="text-align:left;">A few common terms we can search and combine include:</div><p></p><table class="table table-bordered"><tbody><tr><td>Term</td><td>Action</td></tr><tr><td>filetype:<br /></td><td>Search for a file by its extension (e.g. PDF)</td></tr><tr><td>cache:</td><td>View Google\'s Cached version of a specified URL</td></tr><tr><td>intitle:</td><td>The specified phrase MUST appear in the title of the page</td></tr></tbody></table><p></p><div style="text-align:left;">For example, let\'s say we wanted to use Google to search for all PDFs on bbc.co.uk:</div><div style="text-align:left;"><br /></div><div style="text-align:left;"><code>site:bbc.co.uk\xa0filetype:pdf</code></div><div style="text-align:left;"><br /></div><div style="text-align:left;"><img src="https://i.imgur.com/xoDtXnA.png" style="width:563.8px;height:462.041px;" /></div><div style="text-align:left;">Great, now we\'ve refined our search for Google to query for all publically accessible PDFs on "<b>bbc.co.uk</b>" - You wouldn\'t have found files like this "Freedom of Information Request Act" file from a wordlist!</div><div style="text-align:left;"><br /></div><div style="text-align:left;">Here we used the extension <b>PDF</b>, but can you think of any other file formats of sensitive nature that <b>may </b>be publically accessible? (Often unintentionally!!) Again, what you do with any results that you find is where the legality comes into play - this is why "Google Dorking" is so great/dangerous.</div><div style="text-align:left;"><br /></div><div style="text-align:left;">Here is simple directory traversal.</div><div style="text-align:left;"><br /></div><div style="text-align:left;"><b>I have blanked out a lot of the below to cover you, me, THM and the owners of the domains:</b></div><div style="text-align:left;"><img src="https://i.imgur.com/24OH1Kk.png" style="width:590.354px;height:497.656px;" /></div><div style="text-align:left;"><br /></div><div style="text-align:left;"><br /></div><div style="text-align:left;"><br /></div><div style="text-align:left;"><img src="https://i.imgur.com/o0Cnm1P.png" style="width:553.354px;height:423.318px;" /></div><p></p><p></p>', 'taskType': 'none', 'taskNo': 6, 'taskCreated': '2020-03-18T13:34:40.379Z', 'taskDeadline': None, 'tasksInfo': [], 'uploadId': '', 'questions': [{'questionNo': 1, 'question': '<p>What would be the format used to query the site bbc.co.uk about flood defences<br /></p>', 'hint': 'site:bbc.co.uk &lt;query>'}, {'questionNo': 2, 'question': '<p>What term would you use to search by file type?</p>', 'hint': ''}, {'questionNo': 3, 'question': '<p>What term can we use to look for login pages?</p>', 'hint': 'term: query'}]}]}